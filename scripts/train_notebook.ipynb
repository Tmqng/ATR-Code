{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Tmqng/ATR-Code"
      ],
      "metadata": {
        "id": "MfcfSNaxMwKx",
        "outputId": "ef456a3f-a7f0-482b-93db-6dd89ecc402d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MfcfSNaxMwKx",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ATR-Code'...\n",
            "remote: Enumerating objects: 316, done.\u001b[K\n",
            "remote: Counting objects: 100% (316/316), done.\u001b[K\n",
            "remote: Compressing objects: 100% (178/178), done.\u001b[K\n",
            "remote: Total 316 (delta 126), reused 272 (delta 89), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (316/316), 6.93 MiB | 14.91 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "import json\n",
        "import subprocess\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Set up Kaggle credentials\n",
        "kaggle_username = \"minhqunnguyen\"\n",
        "kaggle_api_key = \"KGAT_874d32201f32459c120dc5947083a3d8\"\n",
        "\n",
        "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
        "\n",
        "kaggle_json = {\n",
        "    \"username\": kaggle_username,\n",
        "    \"key\": kaggle_api_key\n",
        "}\n",
        "\n",
        "json_path = os.path.expanduser('~/.kaggle/kaggle.json')\n",
        "with open(json_path, 'w') as f:\n",
        "    json.dump(kaggle_json, f)\n",
        "\n",
        "os.chmod(json_path, 0o600)\n",
        "\n",
        "# Step 2: Verify authentication works\n",
        "result = subprocess.run(['kaggle', 'api', '-v'], capture_output=True, text=True)\n",
        "print(\"Kaggle API version:\", result.stdout)\n",
        "\n",
        "# Step 3: Try downloading your private dataset\n",
        "dataset_identifier = \"minhqunnguyen/mstar-images-et-json\"\n",
        "output_dir = \"/content/ATR-Code/datasets/MSTAR/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Attempting to download: {dataset_identifier}\")\n",
        "!cd {output_dir} && kaggle datasets download -d {dataset_identifier}\n",
        "\n",
        "# Find the zip file\n",
        "zip_file = os.path.join(output_dir, \"mstar-images-et-json.zip\")\n",
        "\n",
        "if os.path.exists(zip_file):\n",
        "    print(f\"Extracting {zip_file}...\")\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(output_dir)\n",
        "    print(\"✓ Done!\")\n",
        "else:\n",
        "    print(f\"Zip file not found at {zip_file}\")\n",
        "    print(f\"Files in {output_dir}:\")\n",
        "    for f in os.listdir(output_dir):\n",
        "        print(f\"  - {f}\")\n",
        "\n",
        "print(\"✓ Download complete!\")"
      ],
      "metadata": {
        "id": "yPDjbN0mNJuC",
        "outputId": "f160f10b-69e7-49bb-ed1f-4e50a12651c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yPDjbN0mNJuC",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API version: \n",
            "Attempting to download: minhqunnguyen/mstar-images-et-json\n",
            "Dataset URL: https://www.kaggle.com/datasets/minhqunnguyen/mstar-images-et-json\n",
            "License(s): unknown\n",
            "Downloading mstar-images-et-json.zip to /content/ATR-Code/datasets/MSTAR\n",
            " 57% 155M/273M [00:00<00:00, 1.62GB/s]\n",
            "100% 273M/273M [00:00<00:00, 968MB/s] \n",
            "Extracting /content/ATR-Code/datasets/MSTAR/mstar-images-et-json.zip...\n",
            "✓ Done!\n",
            "✓ Download complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cfcfcfb0",
      "metadata": {
        "id": "cfcfcfb0"
      },
      "outputs": [],
      "source": [
        "from absl import logging\n",
        "from absl import flags\n",
        "from absl import app\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils import tensorboard\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import torchvision\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get the project root\n",
        "project_root = os.path.join(os.getcwd(), 'ATR-Code')\n",
        "\n",
        "# Add src/ to path\n",
        "sys.path.append(os.path.join(project_root, \"src\"))\n",
        "\n",
        "# modules in src\n",
        "from data.MSTAR.paper_AConvNet import preprocess\n",
        "from data.MSTAR.paper_AConvNet import loader\n",
        "from utils import common\n",
        "from models import AConvNet\n",
        "\n",
        "DATA_PATH = 'datasets/MSTAR/MSTAR_IMG_JSON'\n",
        "\n",
        "# DATA_PATH = 'datasets/MSTAR/mstar_data_paper_AConvNet/'\n",
        "\n",
        "model_str = 'AConvNet'\n",
        "\n",
        "\n",
        "# flags.DEFINE_string('experiments_path', os.path.join(common.project_root, 'experiments'), help='')\n",
        "# flags.DEFINE_string('config_name', f'{model_str}/config/AConvNet-SOC.json', help='')\n",
        "# FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "common.set_random_seed(12321)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e73ef2a4",
      "metadata": {
        "id": "e73ef2a4"
      },
      "outputs": [],
      "source": [
        "logging.info('Start')\n",
        "# experiments_path = FLAGS.experiments_path\n",
        "# config_name = FLAGS.config_name\n",
        "\n",
        "# config = common.load_config(os.path.join(experiments_path, config_name))\n",
        "\n",
        "experiments_path = os.path.join(common.project_root, 'experiments')\n",
        "\n",
        "config = {\n",
        "  \"model_name\": \"AConvNet-SOC\",\n",
        "  \"dataset\": \"SOC\",\n",
        "  \"num_classes\": 10,\n",
        "  \"channels\": 1,\n",
        "  \"batch_size\": 100,\n",
        "  \"epochs\": 2,\n",
        "  \"momentum\": 0.9,\n",
        "  \"lr\": 1e-3,\n",
        "  \"lr_step\": [50],\n",
        "  \"lr_decay\": 0.1,\n",
        "  \"weight_decay\": 4e-3,\n",
        "  \"dropout_rate\": 0.5\n",
        "}\n",
        "\n",
        "dataset = config['dataset']\n",
        "classes = config['num_classes']\n",
        "channels = config['channels']\n",
        "epochs = config['epochs']\n",
        "batch_size = config['batch_size']\n",
        "\n",
        "lr = config['lr']\n",
        "lr_step = config['lr_step']\n",
        "lr_decay = config['lr_decay']\n",
        "\n",
        "weight_decay = config['weight_decay']\n",
        "dropout_rate = config['dropout_rate']\n",
        "\n",
        "model_name = config['model_name']\n",
        "\n",
        "# run(epochs, dataset, classes, channels, batch_size,\n",
        "#     lr, lr_step, lr_decay, weight_decay, dropout_rate,\n",
        "#     model_name, experiments_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7c8edcc8",
      "metadata": {
        "id": "7c8edcc8"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path, is_train, name, batch_size):\n",
        "    \"\"\"\n",
        "    Docstring for load_dataset\n",
        "\n",
        "    :param path: Description\n",
        "    :param is_train: Description\n",
        "    :param name: Description\n",
        "    :param batch_size: Description\n",
        "\n",
        "    Load train, val or test dataset and apply transformations.\n",
        "    \"\"\"\n",
        "\n",
        "    val_transform = torchvision.transforms.Compose([preprocess.CenterCrop(94)])\n",
        "\n",
        "    train_transform = torchvision.transforms.Compose([preprocess.RandomCrop(94)])\n",
        "\n",
        "    _dataset = loader.Dataset(\n",
        "        path, name=name, is_train=is_train,\n",
        "        transform=None\n",
        "    )\n",
        "\n",
        "    if is_train:\n",
        "\n",
        "        # TODO Data_augmentation (in preprocess file)\n",
        "        print(f\"Augmenting training data with patches...\")\n",
        "        # Extract patches from training data\n",
        "        augmented_samples = preprocess.augment_dataset_with_patches(\n",
        "            _dataset,\n",
        "            # patch_size=patch_size,\n",
        "            # stride=stride,\n",
        "            # chip_size=chip_size,\n",
        "            desc=\"Train augmentation\"\n",
        "        )\n",
        "\n",
        "        print(f\"\\nRésultats augmentation :\")\n",
        "        print(f\"  Train : {len(_dataset)} images → {len(augmented_samples)} patches\")\n",
        "        print(f\"  Facteur : ~{len(augmented_samples) / len(_dataset):.0f}x (13x13 = 169 patches/image)\")\n",
        "\n",
        "        augmented_dataset = preprocess.AugmentedDataset(augmented_samples)\n",
        "\n",
        "        # augmented_dataset = _dataset\n",
        "\n",
        "        # Split into train (80%) and validation (20%)\n",
        "        train_size = int(0.8 * len(augmented_dataset))\n",
        "        val_size = len(augmented_dataset) - train_size\n",
        "\n",
        "        train_dataset, val_dataset = random_split(augmented_dataset, [train_size, val_size])\n",
        "\n",
        "        # CenterCrop for val and RandomCrop for train\n",
        "        train_dataset_transformed = preprocess.TransformWrapper(train_dataset, train_transform)\n",
        "        val_dataset_transformed = preprocess.TransformWrapper(val_dataset, val_transform)\n",
        "\n",
        "        train_data_loader = torch.utils.data.DataLoader(\n",
        "            train_dataset_transformed, batch_size=batch_size, shuffle=is_train, num_workers=1\n",
        "        )\n",
        "\n",
        "        val_data_loader = torch.utils.data.DataLoader(\n",
        "            val_dataset_transformed, batch_size=batch_size, shuffle=False, num_workers=1\n",
        "        )\n",
        "\n",
        "        return train_data_loader, val_data_loader\n",
        "\n",
        "\n",
        "    else:\n",
        "        test_dataset_transformed = preprocess.TransformWrapper(_dataset, val_transform)\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            test_dataset_transformed, batch_size=batch_size, shuffle=is_train, num_workers=1\n",
        "        )\n",
        "        return data_loader\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validation(m, ds):\n",
        "    num_data = 0\n",
        "    corrects = 0\n",
        "\n",
        "    # Test loop\n",
        "    m.net.eval()\n",
        "    _softmax = torch.nn.Softmax(dim=1)\n",
        "    for i, data in enumerate(tqdm(ds)):\n",
        "        if i == 0:\n",
        "            print(f\"Data structure: {type(data)}\")\n",
        "            print(f\"Data length: {len(data)}\")\n",
        "            images, labels, _ = data\n",
        "            print(f\"Images shape: {images.shape}\")\n",
        "            print(f\"Labels shape: {labels.shape}\")\n",
        "            print(f\"Unique labels in batch: {torch.unique(labels)}\")\n",
        "        images, labels, _ = data\n",
        "\n",
        "        images = images.to(m.device)\n",
        "        labels = labels.to(m.device)\n",
        "\n",
        "        predictions = m.inference(images)\n",
        "        predictions = predictions.to(m.device)\n",
        "        predictions = _softmax(predictions)\n",
        "\n",
        "        _, predictions = torch.max(predictions.data, 1)\n",
        "\n",
        "        # DEBUG: Check predictions\n",
        "        if i == 0:\n",
        "            print(f\"Predicted classes: {predictions[:10]}\")\n",
        "            print(f\"True labels: {labels[:10]}\")\n",
        "            print(f\"Matches: {(predictions == labels)[:10]}\")\n",
        "\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        num_data += labels.size(0)\n",
        "        corrects += (predictions == labels.to(m.device)).sum().item()\n",
        "\n",
        "    accuracy = 100 * corrects / num_data\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fb55a890",
      "metadata": {
        "id": "fb55a890",
        "outputId": "a10bb8b8-0b18-4f38-bb6b-78832ae9f69e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load train data set: 100%|██████████| 2747/2747 [00:00<00:00, 3169.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmenting training data with patches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train augmentation: 100%|██████████| 2747/2747 [00:08<00:00, 340.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Résultats augmentation :\n",
            "  Train : 2747 images → 134603 patches\n",
            "  Facteur : ~49x (13x13 = 169 patches/image)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load test data set: 100%|██████████| 2425/2425 [00:00<00:00, 3111.45it/s]\n"
          ]
        }
      ],
      "source": [
        "# Décomposition de la fonction run\n",
        "\n",
        "# Load data\n",
        "train_set, val_set = load_dataset(DATA_PATH, True, dataset, batch_size)\n",
        "test_set = load_dataset(DATA_PATH, False, dataset, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "path = os.path.join(project_root, \"datasets/MSTAR/MSTAR_IMG_JSON/SOC\")\n",
        "\n",
        "# Dictionary to store class_ids by folder\n",
        "train_classes = defaultdict(set)\n",
        "test_classes = defaultdict(set)\n",
        "\n",
        "# Check train folder\n",
        "train_path = os.path.join(path, 'train')\n",
        "for class_folder in os.listdir(train_path):\n",
        "    class_folder_path = os.path.join(train_path, class_folder)\n",
        "    if os.path.isdir(class_folder_path):\n",
        "        for file in os.listdir(class_folder_path):\n",
        "            if file.endswith('.json'):\n",
        "                json_path = os.path.join(class_folder_path, file)\n",
        "                with open(json_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "                    class_id = data.get('class_id')\n",
        "                    train_classes[class_folder].add(class_id)\n",
        "\n",
        "# Check test folder\n",
        "test_path = os.path.join(path, 'test')\n",
        "for class_folder in os.listdir(test_path):\n",
        "    class_folder_path = os.path.join(test_path, class_folder)\n",
        "    if os.path.isdir(class_folder_path):\n",
        "        for file in os.listdir(class_folder_path):\n",
        "            if file.endswith('.json'):\n",
        "                json_path = os.path.join(class_folder_path, file)\n",
        "                with open(json_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "                    class_id = data.get('class_id')\n",
        "                    test_classes[class_folder].add(class_id)\n",
        "\n",
        "# Print results\n",
        "print(\"=\"*60)\n",
        "print(\"TRAIN SET - class_id values by folder:\")\n",
        "print(\"=\"*60)\n",
        "for folder in sorted(train_classes.keys()):\n",
        "    print(f\"{folder:20s}: {train_classes[folder]}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEST SET - class_id values by folder:\")\n",
        "print(\"=\"*60)\n",
        "for folder in sorted(test_classes.keys()):\n",
        "    print(f\"{folder:20s}: {test_classes[folder]}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Train folders: {len(train_classes)}\")\n",
        "print(f\"Test folders: {len(test_classes)}\")\n"
      ],
      "metadata": {
        "id": "yz8Zw5IANmib",
        "outputId": "220c7b93-dbf4-45a7-ff42-f9cb15c7751b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yz8Zw5IANmib",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TRAIN SET - class_id values by folder:\n",
            "============================================================\n",
            "2S1                 : {0}\n",
            "BMP2                : {1}\n",
            "BRDM2               : {2}\n",
            "BTR60               : {3}\n",
            "BTR70               : {4}\n",
            "D7                  : {5}\n",
            "T62                 : {6}\n",
            "T72                 : {7}\n",
            "ZIL131              : {8}\n",
            "ZSU234              : {9}\n",
            "\n",
            "============================================================\n",
            "TEST SET - class_id values by folder:\n",
            "============================================================\n",
            "2S1                 : {0}\n",
            "BMP2                : {1}\n",
            "BRDM2               : {2}\n",
            "BTR60               : {3}\n",
            "BTR70               : {4}\n",
            "D7                  : {5}\n",
            "T62                 : {6}\n",
            "T72                 : {7}\n",
            "ZIL131              : {8}\n",
            "ZSU234              : {9}\n",
            "\n",
            "============================================================\n",
            "SUMMARY:\n",
            "============================================================\n",
            "Train folders: 10\n",
            "Test folders: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = AConvNet.Model(\n",
        "    classes=classes, dropout_rate=dropout_rate, channels=channels,\n",
        "    lr=lr, lr_step=lr_step, lr_decay=lr_decay,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "\n",
        "model_path = os.path.join(experiments_path, f'{model_str}/models/{model_name}')\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "history_path = os.path.join(experiments_path, f'{model_str}/history')\n",
        "if not os.path.exists(history_path):\n",
        "    os.makedirs(history_path, exist_ok=True)\n",
        "\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_accuracy': [],\n",
        "    'val_loss': [],\n",
        "    'val_accuracy': []\n",
        "}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    _loss = []\n",
        "\n",
        "    m.net.train()\n",
        "    for i, data in enumerate(tqdm(train_set)):\n",
        "        images, labels, _ = data\n",
        "        _loss.append(m.optimize(images, labels))\n",
        "\n",
        "    if m.lr_scheduler:\n",
        "        lr = m.lr_scheduler.get_last_lr()[0]\n",
        "        m.lr_scheduler.step()\n",
        "\n",
        "    train_accuracy = validation(m, train_set)\n",
        "    val_accuracy = validation(m, val_set)\n",
        "\n",
        "    logging.info(\n",
        "        f'Epoch: {epoch + 1:03d}/{epochs:03d} | loss={np.mean(_loss):.4f} | lr={lr} | Train accuracy={train_accuracy:.2f} | Validation accuracy={val_accuracy:.2f}'\n",
        "    )\n",
        "\n",
        "    history['train_loss'].append(np.mean(_loss))\n",
        "    history['train_accuracy'].append(train_accuracy)\n",
        "    history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "    if experiments_path:\n",
        "        m.save(os.path.join(model_path, f'model-{epoch + 1:03d}.pth'))\n",
        "\n",
        "    with open(os.path.join(history_path, f'history-{model_name}.json'), mode='w', encoding='utf-8') as f:\n",
        "        json.dump(history, f, ensure_ascii=True, indent=2)"
      ],
      "metadata": {
        "id": "DVTHgW90ODk6",
        "outputId": "1cb10b1e-56ec-4875-8c55-7ec64caff45c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DVTHgW90ODk6",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device used: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1077/1077 [00:24<00:00, 43.80it/s]\n",
            "  0%|          | 1/1077 [00:00<03:59,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data structure: <class 'list'>\n",
            "Data length: 3\n",
            "Images shape: torch.Size([100, 1, 94, 94])\n",
            "Labels shape: torch.Size([100])\n",
            "Unique labels in batch: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "Predicted classes: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
            "True labels: tensor([4, 2, 7, 6, 4, 2, 8, 6, 6, 6], device='cuda:0')\n",
            "Matches: tensor([False, False, False,  True, False, False, False,  True,  True,  True],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1077/1077 [00:16<00:00, 63.46it/s]\n",
            "  2%|▏         | 5/270 [00:00<00:10, 24.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data structure: <class 'list'>\n",
            "Data length: 3\n",
            "Images shape: torch.Size([100, 1, 94, 94])\n",
            "Labels shape: torch.Size([100])\n",
            "Unique labels in batch: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "Predicted classes: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
            "True labels: tensor([5, 0, 4, 5, 4, 7, 0, 6, 2, 7], device='cuda:0')\n",
            "Matches: tensor([False, False, False, False, False, False, False,  True, False, False],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 270/270 [00:04<00:00, 58.43it/s]\n",
            "100%|██████████| 1077/1077 [00:22<00:00, 46.83it/s]\n",
            "  0%|          | 5/1077 [00:00<00:42, 25.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data structure: <class 'list'>\n",
            "Data length: 3\n",
            "Images shape: torch.Size([100, 1, 94, 94])\n",
            "Labels shape: torch.Size([100])\n",
            "Unique labels in batch: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "Predicted classes: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
            "True labels: tensor([5, 0, 0, 0, 0, 6, 5, 2, 7, 1], device='cuda:0')\n",
            "Matches: tensor([False, False, False, False, False,  True, False, False, False, False],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1077/1077 [00:17<00:00, 61.93it/s]\n",
            "  2%|▏         | 5/270 [00:00<00:11, 24.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data structure: <class 'list'>\n",
            "Data length: 3\n",
            "Images shape: torch.Size([100, 1, 94, 94])\n",
            "Labels shape: torch.Size([100])\n",
            "Unique labels in batch: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "Predicted classes: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
            "True labels: tensor([5, 0, 4, 5, 4, 7, 0, 6, 2, 7], device='cuda:0')\n",
            "Matches: tensor([False, False, False, False, False, False, False,  True, False, False],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 270/270 [00:04<00:00, 59.02it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}